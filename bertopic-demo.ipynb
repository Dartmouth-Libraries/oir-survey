{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, set explicit parameters\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=5,  # Number of dimensions after dimensionality reduction\n",
    "    min_dist=0.0,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=5,  # Determines how many documents need to be in a topic\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(\"data/raw/2024_COFE_SS_sample_text.csv\")\n",
    "docs = docs.iloc[1:]  # The first row is a comment on the column contents\n",
    "docs = docs.dropna(subset=\"outcometxt\")\n",
    "docs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "sentence_splitter = ChatDartmouth(\n",
    "    model_name=\"llama-3-1-8b-instruct\", seed=42, temperature=0\n",
    ")\n",
    "\n",
    "list_transformer = (\n",
    "    ChatDartmouth(model_name=\"llama-3-1-8b-instruct\", seed=42, temperature=0)\n",
    "    | JsonOutputParser()\n",
    ")\n",
    "\n",
    "SURVEY_PROMPT = \"Please use the space below to describe the most important outcomes of your time as an undergraduate.\"\n",
    "\n",
    "splitter_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            \"The following is a response to the survey prompt '{survey_prompt}'. We want to analyze the topics mentioned in the response. To facilitate this analysis, split the response into stand-alone sentences. Make sure that the sentences can be analyzed in isolation. Make any references to previous sentences explicit by replacing pronouns with their proper noun. Here is the response: \\n\\n{response}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "list_transformer_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a text processor that converts text into valid JSON format.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"The following is a list of sentences. The sentences: \\n\\n{sentences}\"\n",
    "            + 'Reformat them into a JSON using the following schema: ```[\"sentence\": <sentence text>, \"sentence\": <sentence text>]```',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "SAMPLE_RESPONSE = \"My most valuable experiences at Dartmouth had nothing to do with the classes that I was taking; if anything, those classes inhibited my from doing what I actually cared about, which was my extracurricular activities, political advocacy, and social connection, The environment that Dartmouth placed me in gave me the resources and situations necessary to excel at my non-classroom activities, which were the ones that I actually cared about since they will be what I do after I graduate and are what make me happy, \"\n",
    "\n",
    "print(SAMPLE_RESPONSE)\n",
    "print(\"-\" * 20)\n",
    "response = sentence_splitter.invoke(\n",
    "    splitter_prompt.format(survey_prompt=SURVEY_PROMPT, response=SAMPLE_RESPONSE)\n",
    ")\n",
    "response.pretty_print()\n",
    "print(\"-\" * 20)\n",
    "\n",
    "response = list_transformer.invoke(\n",
    "    list_transformer_prompt.format(sentences=response.content)\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[\"outcometxt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(response):\n",
    "    sentences = sentence_splitter.invoke(\n",
    "        splitter_prompt.format(survey_prompt=SURVEY_PROMPT, response=response)\n",
    "    )\n",
    "    result = list_transformer.invoke(\n",
    "        list_transformer_prompt.format(sentences=sentences.content)\n",
    "    )\n",
    "    return [sentence[\"sentence\"] for sentence in result]\n",
    "\n",
    "\n",
    "docs[\"outcometxt\"] = docs[\"outcometxt\"].apply(split_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.explode(column=\"outcometxt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = docs[\"outcometxt\"].dropna().to_list()\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# Fine-tune your topic representations\n",
    "representation_model = KeyBERTInspired()\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    top_n_words=20,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(\n",
    "    responses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = topic_model.get_document_info(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = docs[docs.Topic == 0]\n",
    "subset.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    top_n_words=20,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "subset_topics, probs = subset_topic_model.fit_transform(\n",
    "    subset.Document,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_docs = subset_topic_model.get_document_info(subset.Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_topic_model.visualize_documents(subset_docs.Document.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "subset_docs[[\"Document\", \"Topic\"]].query(\"Topic == 2 or Topic == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distr, _ = topic_model.approximate_distribution(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distr[topic_distr < 0.2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.heatmap(topic_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "topic_distr = pd.DataFrame(topic_distr)\n",
    "topic_distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_association = topic_distr >= 0.2\n",
    "topic_association.corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatDartmouth(model_name=\"llama-3-1-8b-instruct\")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a topic representation model. Your task is to find a representative topic for a collection of similar texts.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the collection of texts that should all be labeled with the same topic representation: {texts} \",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm.invoke(prompt.format(texts=\"A happy dog. \\n\\n A cranky cat.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[\"LLM_representation\"] = None\n",
    "\n",
    "\n",
    "def find_representation(group):\n",
    "    texts = \"\\n\\n\".join(group.Document.to_list())\n",
    "    try:\n",
    "        response = llm.invoke(prompt.format(texts=texts))\n",
    "        group[\"LLM_representation\"] = response.content\n",
    "    except Exception:\n",
    "        pass\n",
    "    return group\n",
    "\n",
    "\n",
    "results = docs.groupby(\"Topic\").apply(find_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[\"LLM_representation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.reset_index(drop=True).groupby(\"Topic\").LLM_representation.unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")\n",
    "sentiment_pipeline(docs[docs.Topic == 0].Document.to_list()[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
