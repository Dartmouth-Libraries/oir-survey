{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility, set explicit parameters\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=5,  # Number of dimensions after dimensionality reduction\n",
    "    min_dist=0.0,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=5,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(\"data/raw/2024_COFE_SS_sample_text.csv\")\n",
    "docs = docs.iloc[1:]  # The first row is a comment on the column contents\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = docs[\"outcometxt\"].dropna().to_list()\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# Fine-tune your topic representations\n",
    "representation_model = KeyBERTInspired()\n",
    "topic_model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    representation_model=representation_model,\n",
    "    top_n_words=20,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(\n",
    "    responses,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_documents(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = topic_model.get_document_info(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distr, _ = topic_model.approximate_distribution(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_distribution(topic_distr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dartmouth_langchain.llms import DartmouthChatModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = DartmouthChatModel(model_name=\"codellama-13b-instruct-hf\")\n",
    "\n",
    "# prompt_template = PromptTemplate.from_template(\n",
    "#     \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "# You are a topic representation model. Your task is to find a representative topic for a collection of similar texts.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "# Here is the collection of texts that should all be labeled with the same topic representation: {texts}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "# )\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"<s>[INST] <<SYS>>\n",
    "You are a topic representation model. Your task is to find a representative topic for a collection of similar texts.\n",
    "<</SYS>>\n",
    "\n",
    "Here is the collection of texts that should all be labeled with the same topic representation: {texts} [/INST] \"\"\"\n",
    ")\n",
    "\n",
    "llm.invoke(prompt_template.format(texts=\"A happy dog. \\n A cranky cat.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[\"LLM_representation\"] = None\n",
    "\n",
    "\n",
    "def find_representation(group):\n",
    "    texts = \"\\n\\n\".join(group.Document.to_list())\n",
    "    try:\n",
    "        response = llm.invoke(prompt_template.format(texts=texts))\n",
    "        group[\"LLM_representation\"] = response\n",
    "    except Exception:\n",
    "        pass\n",
    "    return group\n",
    "\n",
    "\n",
    "results = docs.groupby(\"Topic\").apply(find_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.reset_index(drop=True).groupby(\"Topic\").LLM_representation.unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")\n",
    "sentiment_pipeline(docs[docs.Topic == 0].Document.to_list()[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
