{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain_dartmouth.llms import ChatDartmouth\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "\n",
    "from itertools import batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(\"data/raw/2024_COFE_SS_sample_text.csv\")\n",
    "question = docs.loc[0, \"outcometxt\"]\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.iloc[1:]  # The first row is a comment on the column contents\n",
    "docs = docs.dropna(subset=\"outcometxt\")\n",
    "survey_responses = docs[\"outcometxt\"].to_list()\n",
    "survey_responses[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatDartmouth(\n",
    "    model_name=\"llama-3-1-8b-instruct\",\n",
    "    temperature=0,\n",
    "    seed=42,\n",
    "    max_tokens=60_000,\n",
    ")\n",
    "\n",
    "example_response = (\n",
    "    \"Response ID 1\\n\"\n",
    "    \"Dartmouth has been a transformative experience that's shaped my academic, \"\n",
    "    \"personal, and professional growth. I've gained invaluable knowledge and \"\n",
    "    \"skills through rigorous courses in econ and international relations, which \"\n",
    "    \"have helped me develop a nuanced perspective on global issues. However, I've \"\n",
    "    \"also struggled with the intense academic pressure and lack of diversity in \"\n",
    "    \"certain departments.\\n-----\\n\"\n",
    "    \"Response ID 2\\n\"\n",
    "    \"My time at Dartmouth has been marked by incredible opportunities for growth \"\n",
    "    \"and learning, with notable high points including studying abroad in Asia and \"\n",
    "    \"leading a successful student organization. However, I've also struggled with \"\n",
    "    \"the intense competition for research funding and the sometimes isolating \"\n",
    "    \"Upper Valley setting, which can make it difficult to connect with peers from \"\n",
    "    \"other parts of the country.\"\n",
    ")\n",
    "\n",
    "example_output = \"\"\"[\n",
    "    {{\n",
    "        \"response_id\" : 1,\n",
    "        \"topics\": [\n",
    "            {{\"name\": \"academic and personal growth\", \"sentiment\": \"positive\"}},\n",
    "            {{\"name\": \"academic rigor\", \"sentiment\": \"positive\"}},\n",
    "            {{\"name\": \"academic pressure\", \"sentiment\": \"negative\"}},\n",
    "            {{\"name\": \"lack of diversity\", \"sentiment\": \"negative\"}}\n",
    "        ]\n",
    "    }},\n",
    "    {{\n",
    "        \"response_id\" : 2,\n",
    "        \"topics\": [\n",
    "            {{\"name\": \"Dartmouth student organization experience\", \"sentiment\": \"positive\"}},\n",
    "            {{\"name\": \"study abroad experience\", \"sentiment\": \"positive\"}},\n",
    "            {{\"name\": \"research funding\", \"sentiment\": \"negative\"}},\n",
    "            {{\"name\": \"Upper Valley setting\", \"sentiment\": \"negative\"}}\n",
    "        ]\n",
    "    }}\n",
    "]\"\"\"\n",
    "\n",
    "unlimited_prompt = PromptTemplate.from_template(\n",
    "    (\n",
    "        \"The following are survey responses from students in their senior year at Dartmouth College.\\n\"\n",
    "        \"The prompt was: '{question}'\\n\"\n",
    "        \"Identify the topics mentioned in each response, \"\n",
    "        \"as well as the sentiments expressed towards those topics. \"\n",
    "        \"Format your response in valid JSON. Respond only with the JSON itself. \"\n",
    "        \"Here is an example: \\n\\n\"\n",
    "        \"Response: \\n'\" + example_response + \"'\\n\\n\"\n",
    "        \"Output: \\n\" + example_output + \"\\n\\n\"\n",
    "        \"Here are the responses to process, separated by '\\\\n------\\\\n':\\n\\n\"\n",
    "        \"{responses}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "limited_prompt = PromptTemplate.from_template(\n",
    "    (\n",
    "        \"The following are survey responses from students in their senior year at Dartmouth College.\\n\"\n",
    "        \"The prompt was: '{question}'\\n\"\n",
    "        \"Identify the topics mentioned in each response, \"\n",
    "        \"as well as the sentiments expressed towards those topics. \"\n",
    "        \"The goal is to have a minimal set of topics that represent the common ideas expressed across the responses. \"\n",
    "        \"Do not use more than a total of 15 different topics. \"\n",
    "        \"Format your response in valid JSON. Respond only with the JSON itself. \"\n",
    "        \"Here is an example: \\n\\n\"\n",
    "        \"Response: \\n'\" + example_response + \"'\\n\\n\"\n",
    "        \"Output: \\n\" + example_output + \"\\n\\n\"\n",
    "        \"Here are the responses to process, separated by '\\\\n------\\\\n':\\n\\n\"\n",
    "        \"{responses}\"\n",
    "    )\n",
    ")\n",
    "\n",
    "limited_with_default_prompt = PromptTemplate.from_template(\n",
    "    (\n",
    "        \"The following are survey responses from students in their senior year at Dartmouth College.\\n\"\n",
    "        \"The prompt was: '{question}'\\n\"\n",
    "        \"Identify the topics mentioned in each response, \"\n",
    "        \"as well as the sentiments expressed towards those topics. \"\n",
    "        \"The goal is to have a small number of topics that represent the common ideas expressed across the responses. \"\n",
    "        \"Do not use more than a total of 15 different topics. \"\n",
    "        \"If a response does not fall into any of the 15 topics, label it as 'no-topics'. \"\n",
    "        \"Format your response in valid JSON. Respond only with the JSON itself. \"\n",
    "        \"Here is an example: \\n\\n\"\n",
    "        \"Response: \\n'\" + example_response + \"'\\n\\n\"\n",
    "        \"Output: \\n\" + example_output + \"\\n\\n\"\n",
    "        \"Here are the responses to process, separated by '\\\\n------\\\\n':\\n\\n\"\n",
    "        \"{responses}\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"limited_with_default\"\n",
    "\n",
    "if mode == \"limited_categories\":\n",
    "    prompt = limited_prompt\n",
    "elif mode == \"unlimited_categories\":\n",
    "    prompt = unlimited_prompt\n",
    "elif mode == \"limited_with_default\":\n",
    "    prompt = limited_with_default_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "batch_with_ids = \"\"\n",
    "for id, survey_response in enumerate(survey_responses[:2]):\n",
    "    batch_with_ids += f\"Response ID {id}:\\n{survey_response}\\n------\\n\"\n",
    "for llm_response in chain.stream({\"responses\": batch_with_ids, \"question\": question}):\n",
    "    try:\n",
    "        print(llm_response[-1][\"response_id\"], end=\"\\r\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [item[\"topics\"] for item in llm_response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"id\": range(len(survey_responses)),\n",
    "        \"response\": survey_responses,\n",
    "        \"topics\": topics,\n",
    "    }\n",
    ").explode(\"topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.join(pd.json_normalize(df[\"topics\"]))\n",
    "    .drop(\"topics\", axis=\"columns\")\n",
    "    .drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"data/derived/2024-10-18_naive_llm_{mode}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "- [ ] Rett reviews output of this notebook for all three modalities\n",
    "- Idea 1:\n",
    "  - [ ] Do a pass over all responses prompting the model to identify the 15 most relevant topics expressed across all responses\n",
    "  - [ ] Do a second pass categorizing the responses using only the set of topics identified in the first pass\n",
    "- Idea 2:\n",
    "  - [ ] Determine \"inter-rater reliability\" by running the responses multiple times for different temperatures/seeds\n",
    "  - [ ] Find the overlapping topics identified across the runs\n",
    "  - [ ] Create spreadsheet with results from multiple runs (add a column with run index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
